{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4860e5a-c471-4444-a4d2-632b089aa824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading historical snapshot…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yan\\Desktop\\Python 3.10.6\\lib\\site-packages\\osmnx\\_overpass.py:267: UserWarning: This area is 469 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → download took 18.08 min\n",
      "✅ Written egypt_hwy_only.gpkg\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "OSMNX Road Network Download Block \n",
    "'''\n",
    "\n",
    "# Imports\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import time\n",
    "\n",
    "# year for file paths\n",
    "year = 2018\n",
    "\n",
    "# Set Timestamp\n",
    "timestamp = str(year)+\"-08-01T00:00:00Z\"   \n",
    "\n",
    "# OSMNX Overpass Settings\n",
    "ox.settings.use_cache   = False\n",
    "ox.settings.log_console = True\n",
    "ox.settings.overpass_endpoint = \"https://overpass-api.de/api/interpreter\"   # Specifies default interpreter\n",
    "ox.settings.overpass_settings = (f'[out:json][date:\"{timestamp}\"][timeout:18000]') # Load Timestamp\n",
    "\n",
    "# Filter for road type\n",
    "road_types = (\n",
    "    '[\"highway\"~\"motorway|motorway_link|trunk|trunk_link|'\n",
    "    'primary|primary_link|secondary|secondary_link\"]')          \n",
    "# This line ^^^ should be modified when downloading the 2024 base map, remove secondary/secondary link\n",
    "\n",
    "# Load Graph from OSMNX\n",
    "G = ox.graph_from_place(\n",
    "    \"Egypt\", # Inbuilt Geographic tag\n",
    "    network_type='all_private', #\n",
    "    custom_filter=road_types,\n",
    "    simplify=True, # Ensures proper topology\n",
    "    retain_all=False) # Ignores disconnected fragments\n",
    "\n",
    "# Ensure proper cache for next run\n",
    "ox.settings.use_cache   = True\n",
    "\n",
    "# OSMNX Automatically finds best meter projection\n",
    "G = ox.project_graph(G)\n",
    "\n",
    "# Creates Nodes GDF layer from OSMNX\n",
    "nodes_gdf = ox.graph_to_gdfs(G, nodes=True, edges=False)\n",
    "\n",
    "# Creates Edges GDF Layer from OSMNX\n",
    "records = [] # List to store U,V Pairs\n",
    "for u, v, key, data in G.edges(keys=True, data=True): # Keys and Data ensure proper attribute retrieval for each U,V pair\n",
    "    geom = data.get('geometry',\n",
    "                    LineString([\n",
    "                      (G.nodes[u]['x'], G.nodes[u]['y']),\n",
    "                      (G.nodes[v]['x'], G.nodes[v]['y'])\n",
    "                    ]))\n",
    "    rec = {\n",
    "        'u': u,\n",
    "        'v': v,\n",
    "        'highway': data.get('highway'),\n",
    "        'length': data.get('length'),\n",
    "        'osmid': data.get('osmid'),\n",
    "        'geometry': geom,\n",
    "        'id': data.get('id'),\n",
    "        'lanes': data.get('lanes'),\n",
    "        'oneway': data.get('oneway')\n",
    "    }\n",
    "    records.append(rec)\n",
    "\n",
    "edges_gdf = gpd.GeoDataFrame(records, crs=nodes_gdf.crs)\n",
    "\n",
    "# Save to Geopackage\n",
    "edges_gdf.to_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Egypt\"+str(year)+\"08_01_HW+PR+SE_OSMNX.gpkg\", layer=\"edges\", driver=\"GPKG\")\n",
    "nodes_gdf.to_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Egypt\"+str(year)+\"_08_01_HW+PR+SE_OSMNX.gpkg\", layer=\"nodes\", driver=\"GPKG\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7028c78-2ab6-4ec4-8c65-4f1f9ceb01d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            value                 geometry\n",
      "0        7.640000  POINT (3521250 -253250)\n",
      "1        6.720833  POINT (3521250 -252750)\n",
      "2        5.614286  POINT (3521250 -252250)\n",
      "3       18.533333  POINT (3520750 -253250)\n",
      "4       27.700000  POINT (3520750 -252750)\n",
      "...           ...                      ...\n",
      "125351  24.785714   POINT (2434250 309250)\n",
      "125352   6.722222   POINT (2434250 309750)\n",
      "125353   8.316667   POINT (2434250 346750)\n",
      "125354   8.150000   POINT (2433750 346250)\n",
      "125355  12.237500   POINT (2433750 346750)\n",
      "\n",
      "[125356 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Processing of NTL data Converting the NTL from Raster image to point geometries in ShapeFile \n",
    "\"\"\"\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "# Enter Year of file being processed, does file saving automatically\n",
    "year = 2024\n",
    "\n",
    "# Input raster file path\n",
    "input_path = \"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Nighttime Lights Raster Points/egypt_filtered_nighttime_lights_\"+str(year)+\".tif\"\n",
    "output_path = (\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Nighttime Lights Raster Points/Egypt_NTL_\"+str(year)+\"_Devectorized.shp\")\n",
    "\n",
    "# Using Rasterio to convert raster pixel values to points\n",
    "with rasterio.open(input_path) as src:\n",
    "    data = src.read(1)  # Assuming a single-band raster\n",
    "    transform = src.transform  # Ensures matching coordinates\n",
    "    no_data_value = src.nodata  # Fills in NaNs\n",
    "    crs = CRS.from_epsg(32636) # Sets CRS\n",
    "    \n",
    "# Masks out all pixels with no data\n",
    "if no_data_value is not None:\n",
    "    valid_mask = (data != no_data_value) & np.isfinite(data) & (data > 0)\n",
    "else:\n",
    "    valid_mask = np.isfinite(data) & (data > 0)\n",
    "    \n",
    "rows, cols = np.where(valid_mask)  # Indices of valid pixels\n",
    "\n",
    "# Convert row, col indices to geographic coordinates\n",
    "x_coords, y_coords = rasterio.transform.xy(transform, rows, cols, offset=\"center\")\n",
    "pixel_values = data[rows, cols]  # Get pixel values directly using NumPy indexing\n",
    "\n",
    "# Create geometries (points)\n",
    "geometries = [Point(y, x) for y, x in zip(y_coords, x_coords,)]\n",
    "\n",
    "# Convert to GDF\n",
    "gdf = gpd.GeoDataFrame({\"value\": pixel_values}, geometry=geometries, crs=crs)\n",
    "\n",
    "# Debug\n",
    "print(gdf)\n",
    "\n",
    "# Save\n",
    "gdf.to_file(output_path, driver=\"ESRI Shapefile\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c8b69be-44d8-43f1-98e3-f5516a1ac572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 u            v     highway      length  \\\n",
      "0         38566657   6303863521     primary  441.699889   \n",
      "1         38566657   7843867591     primary  133.532631   \n",
      "2       6303863521   6040298543     primary   47.307494   \n",
      "3       6303863521     38566657     primary  441.699889   \n",
      "4       7843867591   6303863546     primary  158.056940   \n",
      "...            ...          ...         ...         ...   \n",
      "46932   7826432526  10704280124       trunk   92.116208   \n",
      "46933  11005447178  11005447179  trunk_link   23.190743   \n",
      "46934  11005586851  11005586884       trunk   49.608574   \n",
      "46935  11005586884  11005586881  trunk_link   10.141817   \n",
      "46936  11005586884   1167516307       trunk  162.931446   \n",
      "\n",
      "                                      osmid    id lanes  oneway  \\\n",
      "0                                 673142480  None  None   False   \n",
      "1                                 673142476  None  None    True   \n",
      "2                                 673142474  None  None    True   \n",
      "3                                 673142480  None  None   False   \n",
      "4                                 673142476  None  None    True   \n",
      "...                                     ...   ...   ...     ...   \n",
      "46932  [1184793549, 1184793550, 1184793551]  None  None    True   \n",
      "46933                            1184793556  None  None   False   \n",
      "46934                            1150717111  None  None    True   \n",
      "46935                            1184810310  None  None   False   \n",
      "46936                            1150717111  None  None    True   \n",
      "\n",
      "                                                geometry  \n",
      "0      MULTILINESTRING ((491296.184 2659595.387, 4913...  \n",
      "1      MULTILINESTRING ((491296.184 2659595.387, 4912...  \n",
      "2      MULTILINESTRING ((491725.481 2659687.855, 4917...  \n",
      "3      MULTILINESTRING ((491725.481 2659687.855, 4916...  \n",
      "4      MULTILINESTRING ((491167.058 2659626.499, 4911...  \n",
      "...                                                  ...  \n",
      "46932  MULTILINESTRING ((-251207.763 3519919.36, -251...  \n",
      "46933  MULTILINESTRING ((-251375.571 3520033.605, -25...  \n",
      "46934  MULTILINESTRING ((-252919.649 3520827.087, -25...  \n",
      "46935  MULTILINESTRING ((-252969.35 3520825.551, -252...  \n",
      "46936  MULTILINESTRING ((-252969.35 3520825.551, -252...  \n",
      "\n",
      "[46937 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TAKES OSMNX DATA AND EXPLODES MULTILINESTRINGS AND ADDS ADDITIONAL VERTICES EVERY 100M\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "\n",
    "# Year Variable for file paths\n",
    "year = 2023\n",
    "\n",
    "gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_06_01_QGIS_Clipped.gpkg\", layer=\"edges\")\n",
    "output_path = (\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_06_01_Step1_interpolated.gpkg\")\n",
    "\n",
    "# Set CRS\n",
    "gdf = gdf.set_crs(\"EPSG:32636\", allow_override=True)\n",
    "print(gdf)\n",
    "# Drop Unnecessary Columns\n",
    "gdf_columns = gdf.columns\n",
    "gdf_necessary_columns = ['osmid','lanes', 'geometry', 'highway','oneway']\n",
    "\n",
    "for x in gdf_columns:\n",
    "    if x in gdf_necessary_columns:\n",
    "        pass\n",
    "    else: \n",
    "        gdf = gdf.drop(columns = [x])\n",
    "\n",
    "# Turns Oneway info to integers\n",
    "gdf[\"oneway\"] = gdf[\"oneway\"].map({\n",
    "    \"yes\": 1,\n",
    "    \"-1\": -1,\n",
    "    \"no\": 0\n",
    "}).fillna(0)\n",
    "\n",
    "\n",
    "# Splits multiLinestrings into individual linestrings\n",
    "def split_multilinestring(row, id_column, start_id):\n",
    "    #Empty List\n",
    "    geometries = []\n",
    "\n",
    "    #Grab Row info to preserve attributes\n",
    "    base_id = row[id_column]\n",
    "    geometry = row['geometry']\n",
    "\n",
    "    \n",
    "    if geometry.geom_type == 'MultiLineString':\n",
    "        original_start = geometry.geoms[0].coords[0] #Get first and last point of entire multilinestring \n",
    "        original_end = geometry.geoms[-1].coords[-1]\n",
    "        \n",
    "        for i, line in enumerate(geometry.geoms): # In case a line is split, a new, unique ID is given\n",
    "            new_row = row.copy()\n",
    "            new_row[id_column] = f\"{base_id}_{i + start_id}\"\n",
    "\n",
    "            # Check direction of sub-line\n",
    "            sub_start, sub_end = line.coords[0], line.coords[-1]\n",
    "            dist_to_start = Point(sub_start).distance(Point(original_start))\n",
    "            dist_to_end = Point(sub_end).distance(Point(original_start))\n",
    "\n",
    "            if dist_to_end < dist_to_start:\n",
    "                line = LineString(list(line.coords)[::-1])  # reverse if misaligned\n",
    "            \n",
    "            # Add subline to main geometries list\n",
    "            new_row['geometry'] = line\n",
    "            geometries.append(new_row)\n",
    "\n",
    "    #Add Linestring to empty list\n",
    "    elif geometry.geom_type == 'LineString':\n",
    "        geometries.append(row)  # direction is preserved\n",
    "\n",
    "    return geometries\n",
    "\n",
    "\n",
    "# Reassemble gdf with split linestrings\n",
    "id_column = 'osmid'  # Replace with the actual column name for IDs\n",
    "start_id = 1  # Starting integer for the extra ID\n",
    "split_rows = []\n",
    "for _, row in gdf.iterrows():\n",
    "   split_rows.extend(split_multilinestring(row, id_column, start_id))\n",
    "gdf = gpd.GeoDataFrame(split_rows, crs=gdf.crs)\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_line_with_nodes(line, distance):\n",
    "    \"\"\"\n",
    "    Adds points along a LineString every `distance` meters.\n",
    "    Keeps original points and adds interpolated ones.\n",
    "    \"\"\"\n",
    "    # Extract existing points\n",
    "    existing_points = list(line.coords)\n",
    "\n",
    "    # Generate interpolated points\n",
    "    interpolated_points = [line.interpolate(d).coords[0] for d in np.arange(0, line.length, distance)]\n",
    "    interpolated_points.append(line.interpolate(line.length).coords[0])  # Ensure the endpoint is included\n",
    "\n",
    "    # Combine original and interpolated points\n",
    "    all_points = sorted(existing_points + interpolated_points, key=lambda p: line.project(Point(p)))\n",
    "\n",
    "    # Ensure no duplicates in the final LineString\n",
    "    all_points = list(dict.fromkeys(all_points))  # Remove duplicates while preserving order\n",
    "\n",
    "    # Print debugging information\n",
    "    #print(f\"Line segment length: {line.length:.2f} meters\")\n",
    "    #print(f\"Points before: {len(existing_points)}, Points after: {len(all_points)}\")\n",
    "    #print(\"-\" * 50)\n",
    "\n",
    "    return LineString(all_points)\n",
    "\n",
    "# Iterate over dataframe by line, apply interpolate with nodes. Important to note that since CRS is in 32636, 100 is in meters\n",
    "gdf['geometry'] = gdf['geometry'].apply(lambda line: interpolate_line_with_nodes(line, 100))\n",
    "#print(gdf)\n",
    "\n",
    "# Create a new GeoDataFrame\n",
    "new_gdf = gpd.GeoDataFrame(gdf, crs=gdf.crs)\n",
    "\n",
    "# Export\n",
    "new_gdf.to_file(output_path, layer=\"edges\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4de8110a-7737-4516-ba3a-2aca62a0c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TAKES NTL POINTS AND EXPLODED OSMNX MAP AND ADDS NORMALIZED PRIORITY SCORES TO ALL THE POINTS\n",
    "'''\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Year Variable for file paths\n",
    "#year = 2022\n",
    "\n",
    "# Load the shapefiles\n",
    "ntlpoints_gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\n",
    "                              \"/Nighttime Lights Raster Points/Egypt_NTL_\"+str(year)+\"_Devectorized.shp\")\n",
    "roads_gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\n",
    "                          \"/Road Network/Egypt_\"+str(year)+\"_06_01_Step1_interpolated.gpkg\", layer=\"edges\")\n",
    "\n",
    "# Output paths\n",
    "output_path = (\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\n",
    "               \"/Road Network/Egypt_\"+str(year)+\"_Step2_NTL_priorities_added.gpkg\")\n",
    "\n",
    "# These should be set to 32636 to begin with but double check \n",
    "ntlpoints_gdf = ntlpoints_gdf.to_crs(epsg=32636)\n",
    "roads_gdf = roads_gdf.to_crs(epsg=32636)\n",
    "\n",
    "# Extract list of unique nodes for comparison with NTL points\n",
    "unique_nodes = {}\n",
    "for idx, row in roads_gdf.iterrows():\n",
    "    line_id = row['osmid'] #osmid is osmnx provided id column\n",
    "    geometry = row['geometry']\n",
    "    \n",
    "    if geometry.geom_type == 'LineString':\n",
    "        for coord in geometry.coords:\n",
    "            if coord not in unique_nodes: #prevents duplicates\n",
    "                unique_nodes[coord] = {'osmid': line_id, 'coords': coord, 'geometry': Point(coord)} #append\n",
    "\n",
    "# Create a GeoDataFrame for unique linestring nodes\n",
    "nodes_list = list(unique_nodes.values())\n",
    "nodes_gdf = gpd.GeoDataFrame(nodes_list, geometry='geometry', crs=roads_gdf.crs)\n",
    "\n",
    "#set default prio_score to low number but not 0, prevent possible divide by 0\n",
    "nodes_gdf['prio_score'] = 1e-10\n",
    "\n",
    "#cKDTree allows quick search via spatial index\n",
    "node_coords = np.array(list(unique_nodes.keys()))\n",
    "tree = cKDTree(node_coords)\n",
    "\n",
    "#Build list of the road network nodes closest to each NTL point, and the distance to it\n",
    "distances = []            # To store distances\n",
    "closest_node_coords = []  # To store closest node coordinates\n",
    "closest_node_ids = []     # To store closest node IDs\n",
    "\n",
    "#Filter out invalid points, zeroes and infinity\n",
    "ntlpoints_gdf[\"geometry\"] = ntlpoints_gdf[\"geometry\"].apply(lambda g: Point(0, 0) if not g or not np.isfinite(g.x) or not np.isfinite(g.y) else g)\n",
    "\n",
    "#Find the nearest node and store information about it\n",
    "for point in ntlpoints_gdf.geometry: # Loop over all NTL points\n",
    "    dist, idx = tree.query((point.x, point.y)) #use KDTree to find nearest node. Tree is built from road network nodes\n",
    "    distances.append(dist)\n",
    "    nearest_coord = tuple(node_coords[idx])\n",
    "    closest_node_coords.append(nearest_coord)\n",
    "    closest_node_ids.append(unique_nodes[nearest_coord]['osmid'])\n",
    "\n",
    "### This section calculatutes NTL Priority Scores\n",
    "\n",
    "# Add the results as attributes to the points GeoDataFrame\n",
    "ntlpoints_gdf['distance_to_node'] = distances\n",
    "ntlpoints_gdf['closest_node_coords'] = closest_node_coords\n",
    "ntlpoints_gdf['closest_line_id'] = closest_node_ids\n",
    "\n",
    "# Needed variables for normalization\n",
    "max_priority = ntlpoints_gdf['value'].max()\n",
    "max_distance = ntlpoints_gdf['distance_to_node'].max()\n",
    "\n",
    "\n",
    "# Normalizes the light intensity value of the NTL pixel\n",
    "ntlpoints_gdf['normalized_priority'] = ntlpoints_gdf['value'] / max_priority\n",
    "\n",
    "# Normalizes the \"Distance factor\" of each NTl pixel\n",
    "ntlpoints_gdf['normalized_distance'] = ntlpoints_gdf['distance_to_node'] / max_distance\n",
    "\n",
    "# Computes prio_score by dividing normalized priority over normalized distance, plus decimal for DB0\n",
    "ntlpoints_gdf['prio_score'] = ntlpoints_gdf['normalized_priority'] / ntlpoints_gdf['normalized_distance'] + 1e-11\n",
    "\n",
    "### This section takes the NTL Priority scores and adds them to the nearest nodes on the road network\n",
    "\n",
    "# Create a mapping from node coordinates (tuple) to index in nodes_gdf.\n",
    "node_index_map = {tuple(geom.coords[0]): idx for idx, geom in enumerate(nodes_gdf['geometry'])}\n",
    "\n",
    "\n",
    "# Iterate over the points and update the nearest node's priority score\n",
    "for _, point_row in ntlpoints_gdf.iterrows():\n",
    "    point_priority = point_row['prio_score']\n",
    "    nearest_node_coords = point_row['closest_node_coords']  #Store as values for analysis\n",
    "    # Ensure nearest_node_coords is a tuple.\n",
    "    if isinstance(nearest_node_coords, np.ndarray):\n",
    "        nearest_node_coords = tuple(nearest_node_coords)\n",
    "    if nearest_node_coords in node_index_map:\n",
    "        node_idx = node_index_map[nearest_node_coords]\n",
    "        nodes_gdf.at[node_idx, 'prio_score'] += point_priority\n",
    "\n",
    "# Create a mapping of node coordinates to priority scores.\n",
    "node_prio_score_map = nodes_gdf.set_index(\n",
    "    nodes_gdf['geometry'].apply(lambda geom: tuple(geom.coords[0]))\n",
    ")['prio_score'].to_dict()\n",
    "\n",
    "# Create a new GeoDataFrame for nodes using the mapping.\n",
    "node_coords = list(node_prio_score_map.keys())\n",
    "prio_scores = list(node_prio_score_map.values())\n",
    "\n",
    "nodes_layer = gpd.GeoDataFrame(\n",
    "    {\"prio_score\": prio_scores},\n",
    "    geometry=[Point(coord) for coord in node_coords],\n",
    "    crs=nodes_gdf.crs\n",
    ")\n",
    "\n",
    "#Create backup id index\n",
    "nodes_layer[\"id\"] = nodes_layer.index.astype(str)\n",
    "\n",
    "#debug\n",
    "#print(roads_gdf)\n",
    "\n",
    "# Save the updated datasets, including the new nodes layer. nodes will be the vertices on the roads, while we save NTL points just for future reference, not mandatory\n",
    "ntlpoints_gdf.to_file(output_path, layer=\"points\", driver=\"GPKG\")\n",
    "roads_gdf.to_file(output_path, layer=\"edges\", driver=\"GPKG\")\n",
    "nodes_layer.to_file(output_path, layer=\"nodes\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd35af5-b97d-4ce4-8a1e-2ee18e1142b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       highway        osmid     lanes  oneway  \\\n",
      "0      primary    5376791_1  2.633406     0.0   \n",
      "1      primary    5376791_1  2.633406     0.0   \n",
      "2      primary    5376791_1  2.633406     0.0   \n",
      "3      primary    5376791_1  2.633406     0.0   \n",
      "4      primary    5376791_1  2.633406     0.0   \n",
      "...        ...          ...       ...     ...   \n",
      "16301    trunk  101123308_1  2.226917     0.0   \n",
      "16302    trunk  101123223_1  2.226917     0.0   \n",
      "16303    trunk  101123237_1  2.226917     0.0   \n",
      "16304    trunk  101123285_1  2.226917     0.0   \n",
      "16305    trunk  101123223_1  2.226917     0.0   \n",
      "\n",
      "                                                geometry  \n",
      "0      LINESTRING (488036.749 2659087.016, 488098.336...  \n",
      "1      LINESTRING (488036.749 2659087.016, 487945.482...  \n",
      "2      LINESTRING (488098.336 2659089.422, 488036.749...  \n",
      "3      LINESTRING (488098.336 2659089.422, 488163.269...  \n",
      "4      LINESTRING (487842.988 2659092.239, 487881.371...  \n",
      "...                                                  ...  \n",
      "16301  LINESTRING (-251997.022 3520356.145, -252041.9...  \n",
      "16302  LINESTRING (-252041.081 3520301.81, -252011.68...  \n",
      "16303  LINESTRING (-252001.592 3520406.823, -252017.1...  \n",
      "16304  LINESTRING (-252001.592 3520406.823, -252078.9...  \n",
      "16305  LINESTRING (-253078.562 3520860.593, -253061.1...  \n",
      "\n",
      "[16306 rows x 5 columns]\n",
      "       highway        osmid     lanes  oneway  \\\n",
      "0      primary    5376791_1  2.633406     0.0   \n",
      "1      primary    5376791_1  2.633406     0.0   \n",
      "2      primary    5376791_1  2.633406     0.0   \n",
      "3      primary    5376791_1  2.633406     0.0   \n",
      "4      primary    5376791_1  2.633406     0.0   \n",
      "...        ...          ...       ...     ...   \n",
      "16301    trunk  101123308_1  2.226917     0.0   \n",
      "16302    trunk  101123223_1  2.226917     0.0   \n",
      "16303    trunk  101123237_1  2.226917     0.0   \n",
      "16304    trunk  101123285_1  2.226917     0.0   \n",
      "16305    trunk  101123223_1  2.226917     0.0   \n",
      "\n",
      "                                                geometry  \n",
      "0      LINESTRING (488036.749 2659087.016, 488098.336...  \n",
      "1      LINESTRING (488036.749 2659087.016, 487945.482...  \n",
      "2      LINESTRING (488098.336 2659089.422, 488036.749...  \n",
      "3      LINESTRING (488098.336 2659089.422, 488163.269...  \n",
      "4      LINESTRING (487842.988 2659092.239, 487881.371...  \n",
      "...                                                  ...  \n",
      "16301  LINESTRING (-251997.022 3520356.145, -252041.9...  \n",
      "16302  LINESTRING (-252041.081 3520301.81, -252011.68...  \n",
      "16303  LINESTRING (-252001.592 3520406.823, -252017.1...  \n",
      "16304  LINESTRING (-252001.592 3520406.823, -252078.9...  \n",
      "16305  LINESTRING (-253078.562 3520860.593, -253061.1...  \n",
      "\n",
      "[16306 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ASSIGNS MISSING LANE NUMBERS TO EDGES SO THAT ROAD PRIO SCORE CAN BE CALCULATED\n",
    "'''\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Year for file paths\n",
    "#year = 2022\n",
    "\n",
    "# Load the edges layer\n",
    "edges_gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_Step2_NTL_priorities_added.gpkg\", layer='edges')\n",
    "nodes_gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_Step2_NTL_priorities_added.gpkg\", layer='nodes')\n",
    "output_path = \"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_Step3_Lane_Adjusted.gpkg\"\n",
    "print(edges_gdf)\n",
    "\n",
    "# Convert \"lanes\" to integer, handle NaN\n",
    "edges_gdf['lanes'] = pd.to_numeric(edges_gdf['lanes'], errors='coerce')  # Convert non-numeric to NaN\n",
    "\n",
    "# For highways without marked lane numbers, we are using the average of all roads with lanes.\n",
    "avg_lanes_per_highway = edges_gdf.groupby('highway')['lanes'].mean()\n",
    "\n",
    "# Define a function to fill missing lane values with average based on highway type\n",
    "def fill_missing_lanes(row):\n",
    "    if pd.isna(row['lanes']):  # If there is no existing lane count, then apply mean\n",
    "        return avg_lanes_per_highway.get(row['highway'], 1)  # Default to 1 lane if no data for that highway type\n",
    "    return row['lanes']\n",
    "\n",
    "# Apply function to fill missing lane values\n",
    "edges_gdf['lanes'] = edges_gdf.apply(fill_missing_lanes, axis=1)\n",
    "\n",
    "# debug\n",
    "#print(\"Original missing lane values:\", edges_gdf['lanes'].isna().sum())\n",
    "#print(\"Missing lane values after filling:\", edges_gdf['lanes'].isna().sum())\n",
    "\n",
    "# Save the updated dataset back to the GeoPackage\n",
    "\n",
    "nodes_gdf.to_file(output_path, layer=\"nodes\", driver=\"GPKG\")\n",
    "edges_gdf.to_file(output_path, layer=\"edges\", driver=\"GPKG\")\n",
    "# Debug\n",
    "print(edges_gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc1e1106-fe82-4a75-be65-58f70910e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          highway                                   osmid     lanes  oneway  \\\n",
      "0         primary                             673142480_1  2.570527     0.0   \n",
      "1         primary                             673142476_1  2.570527     0.0   \n",
      "2         primary                             673142474_1  2.570527     0.0   \n",
      "3         primary                             673142480_1  2.570527     0.0   \n",
      "4         primary                             673142476_1  2.570527     0.0   \n",
      "...           ...                                     ...       ...     ...   \n",
      "47339       trunk  [1184793549, 1184793550, 1184793551]_1  2.462956     0.0   \n",
      "47340  trunk_link                            1184793556_1  1.725490     0.0   \n",
      "47341       trunk                            1150717111_1  2.462956     0.0   \n",
      "47342  trunk_link                            1184810310_1  1.725490     0.0   \n",
      "47343       trunk                            1150717111_1  2.462956     0.0   \n",
      "\n",
      "                                                geometry  \n",
      "0      LINESTRING (491296.184 2659595.387, 491317.678...  \n",
      "1      LINESTRING (491296.184 2659595.387, 491270.208...  \n",
      "2      LINESTRING (491725.481 2659687.855, 491731.012...  \n",
      "3      LINESTRING (491725.481 2659687.855, 491688.716...  \n",
      "4      LINESTRING (491167.058 2659626.499, 491160.615...  \n",
      "...                                                  ...  \n",
      "47339  LINESTRING (-251207.763 3519919.36, -251203.76...  \n",
      "47340  LINESTRING (-251375.571 3520033.605, -251366.1...  \n",
      "47341  LINESTRING (-252919.649 3520827.087, -252922.7...  \n",
      "47342  LINESTRING (-252969.35 3520825.551, -252973.01...  \n",
      "47343  LINESTRING (-252969.35 3520825.551, -252978.95...  \n",
      "\n",
      "[47344 rows x 5 columns]\n",
      "intersections: 25500\n",
      "prios 1\n",
      "deadends 3402\n"
     ]
    }
   ],
   "source": [
    "''' Creates Proper Road Network by splitting the\n",
    "    road network along each point with high prior score, \n",
    "    intersection points, Assigns Priority scores to Roads '''\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.ops import split\n",
    "from shapely.geometry import MultiPoint, Point, LineString\n",
    "from shapely.strtree import STRtree\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import LineString\n",
    "import uuid\n",
    "\n",
    "\n",
    "# Year for file paths\n",
    "#year = 2022\n",
    "\n",
    "# Load file\n",
    "edges_gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_Step3_Lane_Adjusted.gpkg\", layer='edges')\n",
    "nodes_gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_Step3_Lane_Adjusted.gpkg\", layer='nodes')\n",
    "output_path = \"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_Step4_MSPL_Ready.gpkg\"\n",
    "print(edges_gdf)\n",
    "\n",
    "# Check for proper CRS, most likely redundant but good to check\n",
    "edges_gdf = edges_gdf.to_crs(epsg=32636)\n",
    "nodes_gdf = nodes_gdf.to_crs(edges_gdf.crs)\n",
    "\n",
    "### The first step in this code block is to isolate all dead-end points, all intersection points and all points on a line\n",
    "### with priority scores over zero, and break up linestrings along them to each point can be assessed in a proper network\n",
    "\n",
    "# Filter for nodes with non-zero priority scores\n",
    "prio_nodes_gdf = nodes_gdf[nodes_gdf['prio_score'] > 1e-10]\n",
    "\n",
    "# First, we will find all dead end points\n",
    "endpoints = []\n",
    "\n",
    "# Get every start and end point in geom\n",
    "for geom in edges_gdf.geometry:\n",
    "    if isinstance(geom, LineString):\n",
    "        coords = list(geom.coords)\n",
    "        endpoints.append(coords[0])\n",
    "        endpoints.append(coords[-1])\n",
    "\n",
    "\n",
    "# Count number of appearances for each endpoint\n",
    "point_counts = Counter(endpoints)\n",
    "\n",
    "# If it shows only once, add the coordinates to the set\n",
    "deadend_coords = [Point(pt) for pt, count in point_counts.items() if count == 1]\n",
    "deadend_set = set((pt.x, pt.y) for pt in deadend_coords)\n",
    "\n",
    "# Filter deadend nodes out of gdf\n",
    "deadend_gdf = nodes_gdf[nodes_gdf.geometry.apply(lambda pt: (pt.x, pt.y) in deadend_set)]\n",
    "\n",
    "# Next, we find all the intersection nodes\n",
    "\n",
    "# Extract all coordinates from all LineStrings\n",
    "all_coords = []\n",
    "\n",
    "#Loop over edges to add them nodes in\n",
    "for geom in edges_gdf.geometry:\n",
    "    if isinstance(geom, LineString):\n",
    "        all_coords.extend(list(geom.coords))\n",
    "\n",
    "# Count how many times each point appears\n",
    "point_counts = Counter(all_coords)\n",
    "\n",
    "# Intersections are points that appear more than twice\n",
    "intersection_coords = [Point(pt) for pt, count in point_counts.items() if count > 2]\n",
    "\n",
    "# Grab the coords of the intersection as tuples\n",
    "intersection_set = set((pt.x, pt.y) for pt in intersection_coords)\n",
    "\n",
    "# Filter nodes_gdf to include only intersection points\n",
    "intersection_gdf = nodes_gdf[nodes_gdf.geometry.apply(lambda pt: (pt.x, pt.y) in intersection_set)]\n",
    "\n",
    "print('intersections:', len(intersection_gdf))\n",
    "print('prios', len(prio_nodes_gdf))\n",
    "print('deadends', len(deadend_gdf))\n",
    "\n",
    "#Create one GDF with all three classes we want to split linestrings by\n",
    "combined_gdf = gpd.GeoDataFrame(\n",
    "    pd.concat([prio_nodes_gdf, deadend_gdf, intersection_gdf], ignore_index=True),\n",
    "    crs=prio_nodes_gdf.crs)\n",
    "\n",
    "# Drop duplicates based on geometry only\n",
    "combined_gdf = combined_gdf.drop_duplicates(subset='geometry')\n",
    "\n",
    "# Debug\n",
    "#print(combined_gdf)\n",
    "\n",
    "# Build a Spatial Index for Fast Edge Lookup\n",
    "spatial_index = STRtree(edges_gdf.geometry)\n",
    "\n",
    "# Takes the points in the combined_gdf, and gets the rows of the edges nearest to them, allowing them to be split\n",
    "multi_point = MultiPoint([pt for pt in combined_gdf.geometry])\n",
    "lines_to_split_idx = spatial_index.query(multi_point)  # Get indices of relevant edges\n",
    "\n",
    "relevant_edges = edges_gdf.iloc[lines_to_split_idx]  # Extract only the edges near candidate nodes\n",
    "\n",
    "# To split linestrings quickly, we will build a numpy array of points we want to split by\n",
    "node_coords = np.array([[pt.x, pt.y] for pt in combined_gdf.geometry])\n",
    "\n",
    "def split_line_optimized(line):\n",
    "    \"\"\"\n",
    "    Splits a LineString at candidate node points, preserving the original geometry's directionality.\n",
    "    \"\"\"\n",
    "    line_coords = np.array(line.coords)\n",
    "    distances = np.linalg.norm(node_coords[:, None] - line_coords, axis=2) # Calculates distance between the node point and vertices\n",
    "    nearby_points = node_coords[np.any(distances < 1e-5, axis=1)] # covers for possible topological mismatches\n",
    "\n",
    "    if len(nearby_points) == 0: #If not near any points, just return it unchanged\n",
    "        return [line]\n",
    "\n",
    "    # Perform split with shapely, splitting line at the points found by nearby_points\n",
    "    split_result = split(line, MultiPoint([Point(p) for p in nearby_points]))\n",
    "    valid_segments = [seg for seg in split_result.geoms if len(seg.coords) > 1] # Removes segments without 2 coords\n",
    "\n",
    "    if not valid_segments:\n",
    "        return [line]\n",
    "\n",
    "    # Sort by projected distance along the original line (preserves direction)\n",
    "    valid_segments = sorted(\n",
    "        valid_segments,\n",
    "        key=lambda seg: line.project(Point(seg.coords[0])))\n",
    "\n",
    "    return valid_segments\n",
    "\n",
    "# Apply the optimized split function to each relevant edge.\n",
    "split_segments = [\n",
    "    {\"geometry\": segment, **row.to_dict()}  # Store original attributes with each segment\n",
    "    for _, row in relevant_edges.iterrows() # Applies this only to edges near points of interest\n",
    "    for segment in split_line_optimized(row.geometry)] #Run functions\n",
    "\n",
    "split_edges_gdf = gpd.GeoDataFrame(split_segments, crs=relevant_edges.crs) # Compile results into new GDF\n",
    "\n",
    "#Debug print statements\n",
    "#print(\"Split Edges GDF:\", split_edges_gdf)\n",
    "#print(\"Edges GDF:\", edges_gdf)\n",
    "#print(\"Combined GDF:\", combined_gdf)\n",
    "\n",
    "### Here, priority scores for edges will be calculated\n",
    "\n",
    "#Calculate the length (in meters) for each edge.\n",
    "split_edges_gdf[\"length_m\"] = split_edges_gdf.geometry.length\n",
    "split_edges_gdf['lanes'] = pd.to_numeric(split_edges_gdf['lanes'], errors='coerce')\n",
    "\n",
    "# Calculate maximum values for normalization.\n",
    "max_length = split_edges_gdf['length_m'].max()\n",
    "max_lanes  = split_edges_gdf['lanes'].max()\n",
    "\n",
    "# Normalize attributes and compute a road priority score capacity/length. This way, higher lanes correlates with a higher score, and longer roads with a lower score. \n",
    "split_edges_gdf['normalized_length'] = split_edges_gdf['length_m'] / max_length # Normalized Length\n",
    "split_edges_gdf['normalized_capacity'] = split_edges_gdf['lanes'] / max_lanes #Normalized Lanecount \"Capacity\"\n",
    "split_edges_gdf[\"road_prio_score\"] = split_edges_gdf[\"normalized_capacity\"] / (split_edges_gdf[\"normalized_length\"] + 1e-6)\n",
    "\n",
    "# Extract start and end coords from each LineString\n",
    "endpoints = set()\n",
    "\n",
    "#store start and end points separately\n",
    "for geom in split_edges_gdf.geometry:\n",
    "    if geom and geom.geom_type == 'LineString':\n",
    "        coords = list(geom.coords)\n",
    "        endpoints.add(coords[0])  \n",
    "        endpoints.add(coords[-1])  \n",
    "\n",
    "# Convert to list of Point geometries\n",
    "unique_endpoints = [Point(xy) for xy in endpoints]\n",
    "\n",
    "# Convert unique endpoint Points to coordinate tuples\n",
    "endpoint_set = set((pt.x, pt.y) for pt in unique_endpoints)\n",
    "\n",
    "# Filter nodes_gdf by checking if each point matches a known endpoint\n",
    "endpoint_gdf = nodes_gdf[nodes_gdf.geometry.apply(lambda pt: (pt.x, pt.y) in endpoint_set)]\n",
    "\n",
    "# Save the edges and nodes layers into the gpkg.\n",
    "\n",
    "split_edges_gdf.to_file(output_path, layer=\"edges\", driver=\"GPKG\")\n",
    "endpoint_gdf.to_file(output_path, layer=\"nodes\", driver=\"GPKG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0120d86-e94d-4dce-878a-ea9f0f9b6141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TQDM VERSION + Sampling + Working version\"\"\"\n",
    "import geopandas as gpd\n",
    "import igraph as ig\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#Year variable\n",
    "year = 2014\n",
    "\n",
    "#Debug, prints file path\n",
    "#edge_path = \"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_analysis_ready_OG.gpkg\"\n",
    "#print(edge_path)\n",
    "\n",
    "# Load GeoDataFrames\n",
    "edges_gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_analysis_ready_OG.gpkg\", layer=\"edges\")\n",
    "nodes_gdf = gpd.read_file(\"C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/\"+str(year)+\"/Road Network/Egypt_\"+str(year)+\"_analysis_ready_OG.gpkg\", layer=\"nodes\")\n",
    "edges_gdf = edges_gdf.rename(columns={\"osmid\":\"id\"})\n",
    "\n",
    "# Ensure all geometries use the same CRS\n",
    "edges_gdf = edges_gdf.to_crs(nodes_gdf.crs)\n",
    "edges_gdf_cleaned = edges_gdf.drop_duplicates()\n",
    "edges_gdf = edges_gdf_cleaned.loc[~edges_gdf_cleaned.duplicated(keep=\"first\")].reset_index(drop=True)\n",
    "\n",
    "# Extract start and end points from each LineString\n",
    "edges_gdf[\"start_geom\"] = edges_gdf.geometry.apply(lambda geom: Point(geom.coords[0]))\n",
    "edges_gdf[\"end_geom\"] = edges_gdf.geometry.apply(lambda geom: Point(geom.coords[-1]))\n",
    "\n",
    "# Convert start/end to GeoDataFrames\n",
    "start_points = gpd.GeoDataFrame(edges_gdf[[\"id\"]], geometry=edges_gdf[\"start_geom\"], crs=edges_gdf.crs)\n",
    "end_points = gpd.GeoDataFrame(edges_gdf[[\"id\"]], geometry=edges_gdf[\"end_geom\"], crs=edges_gdf.crs)\n",
    "\n",
    "# Spatial join to find nearest node for each start and end point\n",
    "start_join = gpd.sjoin_nearest(start_points, nodes_gdf[[\"id\", \"geometry\"]], how=\"left\", distance_col=\"dist\")\n",
    "end_join = gpd.sjoin_nearest(end_points, nodes_gdf[[\"id\", \"geometry\"]], how=\"left\", distance_col=\"dist\")\n",
    "\n",
    "# Merge results back into edges_gdf\n",
    "edges_gdf[\"start_node_id\"] = start_join[\"id_right\"]\n",
    "edges_gdf[\"end_node_id\"] = end_join[\"id_right\"]\n",
    "\n",
    "# Standardize node IDs for igraph\n",
    "nodes_gdf[\"id\"] = nodes_gdf[\"id\"].astype(str)\n",
    "edges_gdf[\"start_node_id\"] = edges_gdf[\"start_node_id\"].astype(str)\n",
    "edges_gdf[\"end_node_id\"] = edges_gdf[\"end_node_id\"].astype(str)\n",
    "\n",
    "valid_ids = set(nodes_gdf[\"id\"])\n",
    "edges_gdf = edges_gdf[\n",
    "    edges_gdf[\"start_node_id\"].isin(valid_ids) &\n",
    "    edges_gdf[\"end_node_id\"].isin(valid_ids)\n",
    "]\n",
    "# Build edge list for igraph\n",
    "edge_list = []\n",
    "edge_ids = []\n",
    "weights = []\n",
    "edge_lengths = []\n",
    "\n",
    "# start storing edges and attributes needed from the gdf in above lists\n",
    "for _, row in edges_gdf.iterrows():\n",
    "    sid = row[\"start_node_id\"]\n",
    "    eid = row[\"end_node_id\"]\n",
    "    edge_id = str(row[\"id\"])\n",
    "    weight = 1 / row[\"road_prio_score\"] if row[\"road_prio_score\"] > 0 else np.inf\n",
    "    length  = row[\"length_m\"]\n",
    "    if row[\"oneway\"] == 1:\n",
    "        edge_list.append((sid, eid))\n",
    "        edge_ids.append(edge_id)\n",
    "        weights.append(weight)\n",
    "        edge_lengths.append(length)\n",
    "\n",
    "    elif row[\"oneway\"] == -1:\n",
    "        edge_list.append((eid, sid))\n",
    "        edge_ids.append(edge_id)\n",
    "        weights.append(weight)\n",
    "        edge_lengths.append(length)\n",
    "    elif row[\"oneway\"] == 0:\n",
    "        edge_list.append((eid, sid))\n",
    "        edge_ids.append(edge_id)\n",
    "        weights.append(weight)\n",
    "        edge_lengths.append(length)\n",
    "\n",
    "\"\"\"UNHASHTAG If USING ONE WAY\"\"\"\n",
    "    #elif row[\"oneway\"] == 0:\n",
    "        #for u, v in [(sid, eid), (eid, sid)]:\n",
    "            #edge_list.append((u, v))\n",
    "            #edge_ids.append(edge_id)\n",
    "            #weights.append(weight)\n",
    "\n",
    "# Create new sets in case any duplicates were stored\n",
    "edge_set = set()\n",
    "clean_edges = []\n",
    "clean_ids = []\n",
    "clean_weights = []\n",
    "clean_lengths = []\n",
    "\n",
    "for (u,v), eid, w, L in zip(edge_list, edge_ids, weights, edge_lengths):\n",
    "    if (u,v) not in edge_set:\n",
    "        edge_set.add((u,v))\n",
    "        clean_edges.append((u, v))\n",
    "        clean_ids.append(eid)\n",
    "        clean_weights.append(w)\n",
    "        clean_lengths.append(L)\n",
    "\n",
    "# Build the graph\n",
    "g = ig.Graph(directed=True)\n",
    "g.add_vertices(nodes_gdf[\"id\"].tolist())\n",
    "g.add_edges(clean_edges)\n",
    "g.es[\"edge_id\"] = clean_ids\n",
    "g.es[\"weight\"] = clean_weights\n",
    "g.es[\"length\"]  = clean_lengths  \n",
    "g.vs[\"prio_score\"] = nodes_gdf.set_index(\"id\").loc[g.vs[\"name\"]][\"prio_score\"].tolist()\n",
    "print(f\"✅ Final graph has {g.vcount()} nodes and {g.ecount()} edges.\")\n",
    "\n",
    "# Extract largest strongly connected component (LSCC) Redundant but just in case\n",
    "largest_cc = g.clusters(mode=\"WEAK\").giant()\n",
    "print(\"LWCC edges:\", largest_cc.ecount())\n",
    "print(\"LWCC nodes:\", largest_cc.vcount())\n",
    "\n",
    "#Set parameters for the graph and analysis\n",
    "full_edges = largest_cc.get_edgelist()\n",
    "lengths    = largest_cc.es[\"length\"]\n",
    "vs       = largest_cc.vs\n",
    "prios    = np.array(vs[\"prio_score\"], dtype=float) #Will use priority scores for node subsampling\n",
    "probs    = prios / prios.sum() #Set probabilities for subsampling\n",
    "k        = min(15000, len(vs)) #Set sample size\n",
    "\n",
    "#Do Sampling using random choice \n",
    "sample_idx = np.random.choice(len(vs), size=k, replace=False, p=probs)\n",
    "\n",
    "#Function to do subsampling\n",
    "def weighted_mspl_sampled(graph, sample_idx):\n",
    "    # get prio weights for the sampled nodes\n",
    "    pr = np.array(graph.vs[\"prio_score\"], dtype=float)[sample_idx]\n",
    "    # compute pairwise shortest‐path distances *only* between those sampled nodes\n",
    "    D  = np.array(graph.shortest_paths_dijkstra(\n",
    "            source=sample_idx,\n",
    "            target=sample_idx,\n",
    "            weights=\"weight\"\n",
    "         ))\n",
    "    # build the outer‐product weight matrix\n",
    "    P  = pr[:,None] * pr[None,:]\n",
    "    # mask upper triangle, finite distances\n",
    "    mask = np.triu(np.isfinite(D), k=1)\n",
    "    return (P[mask] * D[mask]).sum() / P[mask].sum()\n",
    "\n",
    "# 4) Compute your “baseline” on the sample\n",
    "baseline_mspl = weighted_mspl_sampled(largest_cc, sample_idx)\n",
    "print(\"Baseline (sampled) MSPL:\", baseline_mspl)\n",
    "\n",
    "#Filter edges by length for processing\n",
    "full_edges  = largest_cc.get_edgelist()\n",
    "lengths     = largest_cc.es[\"length\"]\n",
    "edge_list   = [(u,v) for (u,v),L in zip(full_edges, lengths) if L > 500] # Only takes edges over 500m, avoid running calculations over tiny segments\n",
    "orig_ids    = [eid for eid,L in zip(largest_cc.es[\"edge_id\"], lengths) if L > 500] \n",
    "orig_wts    = [w   for w, L in zip(largest_cc.es[\"weight\"],    lengths) if L > 500]\n",
    "\n",
    "#Set up calculations for multiprocessing\n",
    "tasks = list(zip(edge_list, orig_ids, orig_wts))\n",
    "\n",
    "# Define function that finds delta_MSPL in a way compatible with multicore processing\n",
    "def process_edge(task):\n",
    "    (u, v), eid, w = task\n",
    "    # find igraph‐internal id and stash original weight\n",
    "    i_eid     = largest_cc.get_eid(u, v)\n",
    "    old_weight = largest_cc.es[i_eid][\"weight\"]\n",
    "\n",
    "    # “remove” the edge by setting weight = ∞\n",
    "    largest_cc.es[i_eid][\"weight\"] = float(\"inf\")\n",
    "\n",
    "    # recompute sampled MSPL\n",
    "    mspl2 = weighted_mspl_sampled(largest_cc, sample_idx)\n",
    "    delta = mspl2 - baseline_mspl\n",
    "\n",
    "    # restore original weight\n",
    "    largest_cc.es[i_eid][\"weight\"] = old_weight\n",
    "\n",
    "    return {\n",
    "        \"id\":  eid,\n",
    "        \"weight\":            w,\n",
    "        \"mspl_after_removal\": mspl2,\n",
    "        \"delta_mspl\":         delta\n",
    "    }\n",
    "\n",
    "# Run \"process_edge\" in parallel on tqdm, n_jobs will correspond to core count\n",
    "with tqdm_joblib(tqdm(desc=\"Processing edges\", total=len(tasks))) as progress_bar:\n",
    "    results = Parallel(n_jobs=4, backend=\"loky\")(\n",
    "        delayed(process_edge)(t) for t in tasks\n",
    "    )\n",
    "\n",
    "# Collect results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# … then your filtering & printing as before …\n",
    "filtered_df = df[\n",
    "    df[\"delta_mspl\"].apply(np.isfinite) &\n",
    "    (df[\"delta_mspl\"] != 0)\n",
    "]\n",
    "\n",
    "results_gdf = edges_gdf.merge(filtered_df, on=\"id\", how=\"left\")\n",
    "results_gdf = results_gdf.drop(['start_geom','end_geom'], axis=1)\n",
    "\n",
    "# Save Result to File\n",
    "results_gdf.to_file('C:/Users/Yan/Desktop/McCord Project Infra/Shapefiles/Egypt/'+str(year)+'/Road Network/Egypt_'+str(year)+'_MSPL_RESULTS_HighParam15000_run1.gpkg', layer=\"edges\", driver=\"GPKG\")\n",
    "\n",
    "###Debug\n",
    "#print(\"Top 10 Positive delta_mspl:\")\n",
    "#print(filtered_df.nlargest(10, \"delta_mspl\")[[\"id\",\"delta_mspl\"]])\n",
    "\n",
    "#print(\"Top 10 Negative delta_mspl:\")\n",
    "#print(filtered_df.nsmallest(10, \"delta_mspl\")[[\"id\",\"delta_mspl\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4ec5d-b617-470a-8110-754b278ca928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
